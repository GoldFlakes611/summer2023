{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "446bcecf",
   "metadata": {},
   "source": [
    "### Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import threading\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#TF Logging is excessive, minimize log spamming by setting level lower\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed (only errors)\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "# On Mac you may encounter an error related to OMP, this is a workaround, but slows down the code\n",
    "# https://github.com/dmlc/xgboost/issues/1715\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d72cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.optimizer.set_jit(True)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e71bec4",
   "metadata": {},
   "source": [
    "## Check if there is any available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "if gpus:\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=15360)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ef8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openbot import utils, train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4388bbaa",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "625eb2bd",
   "metadata": {},
   "source": [
    "You may have to tune the learning rate and batch size depending on your available compute resources and dataset. As a general rule of thumb, if you increase the batch size by a factor of n, you can increase the learning rate by a factor of sqrt(n). In order to accelerate training and make it more smooth, you should increase the batch size as much as possible. For our working model, we used a batch size of 128. For debugging and hyperparamter tuning, you can set the number of epochs to a small value like 10. If you want to train a model which will achieve good performance, you should set it to 200 or more. For our working model, we used 600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c7cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = train.Hyperparameters()\n",
    "params.MODEL = \"resnet\"\n",
    "#Training Parameters\n",
    "params.TRAIN_BATCH_SIZE = 128\n",
    "params.TEST_BATCH_SIZE = 128   \n",
    "params.LEARNING_RATE = 0.0002\n",
    "params.NUM_EPOCHS = 300    #total number of iterations on the full dataset\n",
    "\n",
    "#Data Augmentation Parameters\n",
    "params.BATCH_NORM = False  #normalize the batched data (bad results)\n",
    "params.TRANS_AUG = True    #translate the batched data (good results)\n",
    "params.FLIP_AUG = True     #flip the images and steering angles (safe now for turns)\n",
    "params.USE_LAST = False    #Use last training data\n",
    "\n",
    "#Callback Parameters\n",
    "params.WANDB = False       #Use WANDB to log training metrics\n",
    "params.CHKPT = True        #Save checkpoints at end of every epoch (slows down training)\n",
    "params.LOG = False         #Save logs\n",
    "params.TENSORBOARD = False #Use tensorboard to save data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a4a1cf",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we initiliaze a training object to hold these parameters, set the dataset directories of this object to point to the collected data\n",
    "tr = train.Training(params, None)\n",
    "\n",
    "tr.train_data_dir = <train.tfrec>\n",
    "train.load_tfrecord(tr, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae38ad6a",
   "metadata": {},
   "source": [
    "Sanity check on the batch sampling, make sure the images and the steering/throttle look correct! -1 steering is the maximum left turn and 1.0 is the minimum right turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf34f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: get rid of the print statements for this\n",
    "image_batch, label_batch = next(iter(tr.train_ds))\n",
    "utils.show_train_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a5d0f77",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create broadcast event so we can see the model fit processing\n",
    "def broadcast(event, payload=None):\n",
    "    print(event, payload)\n",
    "    \n",
    "event = threading.Event()\n",
    "my_callback = train.MyCallback(broadcast, event)\n",
    "\n",
    "model, callback_list = train.setup_training(tr, my_callback, \"samsung_train_data\", verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "667e1820",
   "metadata": {},
   "source": [
    "### Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cd54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logdir\")\n",
    "\n",
    "tr.history = model.fit(\n",
    "    tr.train_ds,\n",
    "    epochs=tr.hyperparameters.NUM_EPOCHS,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=tr.test_ds,\n",
    "    verbose=1,\n",
    "    callbacks=[tb_callback]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cfd4aac",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f623b65f",
   "metadata": {},
   "source": [
    "The loss and mean absolute error should decrease. This indicates that the model is fitting the data well. The custom metrics (direction and angle) should go towards 1. These provide some additional insight to the training progress. The direction metric measures weather or not predictions are in the same direction as the labels. Similarly the angle metric measures if the prediction is within a small angle of the labels. The intuition is that driving in the right direction with the correct steering angle is most critical part for good final performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "729d32c4",
   "metadata": {},
   "source": [
    "### Convert to Tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet.tflite\"\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "open(model_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6160138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, uuid\n",
    "path_to_config = \"../android/app/src/main/assets/config.json\"\n",
    "model_input = tflite_model.get_signature_list()['serving_default']['inputs'][0]\n",
    "model_input_name = \"serving_default_\" + model_input + \":0\"\n",
    "with open(path_to_config, 'r+') as f:\n",
    "    data = json.load(f)\n",
    "    data.append({\n",
    "        'id': data[-1]['id']+1,\n",
    "        'class': 'BEHAVIORCLONE_F',\n",
    "        'type': 'BEHAVIORCLONE',\n",
    "        'name': model_name,\n",
    "        'pathType': 'ASSET',\n",
    "        'path': 'networks/' + model_name,\n",
    "        'inputSize': '224x224',\n",
    "        'input_name': model_input_name\n",
    "    })\n",
    "\n",
    "# create randomly named temporary file to avoid \n",
    "# interference with other thread/asynchronous request\n",
    "tempfile = os.path.join(\"../android/app/src/main/assets\", str(uuid.uuid4()))\n",
    "with open(tempfile, 'w') as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "os.replace(tempfile, path_to_config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00bec468",
   "metadata": {},
   "source": [
    "### Loss vs. Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tr.history.history['loss']\n",
    "val_loss = tr.history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd65e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"loss.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8539fda9",
   "metadata": {},
   "source": [
    "### Mean Absolute Error vs. Validation Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error = tr.history.history['mean_absolute_error']\n",
    "val_mean_absolute_error = tr.history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e98f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_absolute_error, label=\"mean_absolute_error\")\n",
    "plt.plot(val_mean_absolute_error, label=\"val_mean_absolute_error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"error.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ab92b34",
   "metadata": {},
   "source": [
    "### Direction Metric vs. Validation Direction Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b86858",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_metric = tr.history.history['direction_metric']\n",
    "val_direction_metric = tr.history.history['val_direction_metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1752d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(direction_metric, label=\"direction_metric\")\n",
    "plt.plot(val_direction_metric, label=\"val_direction_metric\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Direction Metric\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"direction.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea50c71f",
   "metadata": {},
   "source": [
    "### Angle Metric vs. Validation Angle Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1a33ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_metric = tr.history.history['angle_metric']\n",
    "val_angle_metric = tr.history.history['val_angle_metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de04eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(angle_metric, label=\"angle_metric\")\n",
    "plt.plot(val_angle_metric, label=\"val_angle_metric\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Angle Metric\")  \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"angle.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e72c1de3",
   "metadata": {},
   "source": [
    "Save tf lite models for best and last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.argmax(\n",
    "     np.array(tr.history.history[\"val_angle_metric\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    " #best_index = np.argmax(\n",
    " #    np.array(tr.history.history[\"val_angle_metric\"])\n",
    " #    + np.array(tr.history.history[\"val_direction_metric\"])\n",
    "#)\n",
    "#best_index = np.argmax(np.array(tr.history.history[\"val_angle_metric\"]))\n",
    "#best_checkpoint = str(\"cp-%04d.ckpt\" % (best_index + 1))\n",
    "best_checkpoint = \"cp-0060.ckpt\"\n",
    "best_tflite = utils.generate_tflite(tr.checkpoint_path, best_checkpoint)\n",
    "utils.save_tflite(best_tflite, tr.checkpoint_path, \"best_\")\n",
    "'''\n",
    "print(\n",
    "    \"Best Checkpoint (angle_metric: %s, loss: %s, direction_metric: %s): %s\"\n",
    "    % (\n",
    "        tr.history.history[\"val_angle_metric\"][best_index],\n",
    "        tr.history.history[\"val_loss\"][best_index],\n",
    "        tr.history.history[\"val_mean_absolute_error\"][best_index],\n",
    "        best_checkpoint,\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_index = np.argmax(\n",
    "#     np.array(tr.history.history[\"val_angle_metric\"])\n",
    "#     + np.array(tr.history.history[\"val_direction_metric\"])\n",
    "# )\n",
    "best_index = np.argmin(np.array(tr.history.history[\"val_loss\"]))\n",
    "best_checkpoint = str(\"cp-%04d.ckpt\" % (best_index + 1))\n",
    "best_tflite = utils.generate_tflite(tr.checkpoint_path, best_checkpoint)\n",
    "utils.save_tflite(best_tflite, tr.checkpoint_path, \"best_loss\")\n",
    "print(\n",
    "    \"Best Checkpoint (angle_metric: %s, loss: %s, direction_metric: %s): %s\"\n",
    "    % (\n",
    "        tr.history.history[\"val_angle_metric\"][best_index],\n",
    "        tr.history.history[\"val_loss\"][best_index],\n",
    "        tr.history.history[\"val_mean_absolute_error\"][best_index],\n",
    "        best_checkpoint,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb605b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = sorted(\n",
    "    [\n",
    "        d\n",
    "        for d in os.listdir(tr.checkpoint_path)\n",
    "        if os.path.isdir(os.path.join(tr.checkpoint_path, d))\n",
    "    ]\n",
    ")[-1]\n",
    "last_tflite = utils.generate_tflite(tr.checkpoint_path, last_checkpoint)\n",
    "utils.save_tflite(last_tflite, tr.checkpoint_path, \"last\")\n",
    "print(\n",
    "    \"Last Checkpoint (val_angle: %s, val_direction: %s, val_mean_absolute_error: %s): %s\"\n",
    "    % (\n",
    "        tr.history.history[\"val_angle_metric\"][-1],\n",
    "        tr.history.history[\"val_direction_metric\"][-1],\n",
    "        tr.history.history[\"val_mean_absolute_error\"][-1],\n",
    "        last_checkpoint,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0c57018",
   "metadata": {},
   "source": [
    "Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a03c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = utils.load_model(\n",
    "    os.path.join(tr.checkpoint_path, best_checkpoint),\n",
    "    tr.loss_fn,\n",
    "    tr.metric_list,\n",
    "    tr.custom_objects,\n",
    ")\n",
    "test_loss, test_acc, test_dir, test_ang = best_model.evaluate(\n",
    "    tr.test_ds,\n",
    "    steps=tr.image_count_test / tr.hyperparameters.TEST_BATCH_SIZE,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"model_tester.tflite\")\n",
    "steering = []\n",
    "steering2 = []\n",
    "#interpreter.allocate_tensors()\n",
    "\n",
    "my_sign = interpreter.get_signature_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf29453",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac76f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = \"cp-0040.ckpt\"\n",
    "model = utils.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.load_model(\n",
    "    os.path.join(tr.checkpoint_path, \"cp-0060.ckpt\"),\n",
    "    tr.loss_fn,\n",
    "    tr.metric_list,\n",
    "    tr.custom_objects,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e01e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NUM_SAMPLES = 1\n",
    "\n",
    "#while NUM_SAMPLES > 0:\n",
    "image_batch, label_batch = next(iter(tr.test_ds))\n",
    "#tr.test_ds = tr.test_ds.shuffle(15 * 30)\n",
    "#max_ind = np.min((NUM_SAMPLES, 128))\n",
    "pred_batch = model.call(\n",
    "        tf.slice(image_batch, [0, 0, 0, 0], [15, -1, -1, -1]),\n",
    "        training=False\n",
    ")\n",
    "#interpreter.set_tensor(interpreter.get_input_details()[0]['index'], tf.slice(image_batch, [0, 0, 0, 0], [1, -1, -1, -1]).numpy())\n",
    "#interpreter.invoke()\n",
    "#output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
    "#output = my_sign(input_1=tf.slice(image_batch, [0, 0 ,0, 0], [15, -1, -1, -1]))\n",
    "#NUM_SAMPLES -= 1\n",
    "#steering.append(pred_batch.numpy())\n",
    "#steering2.append(output['dense_3'])\n",
    "#print(NUM_SAMPLES)\n",
    "\n",
    "utils.show_test_batch(\n",
    "    image_batch.numpy(), label_batch.numpy(), pred_batch.numpy() #output['dense_3']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f38d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig,ax = plt.subplots(2,1)\n",
    "#steering_fixed = np.concatenate(steering, axis=0)[:,1]\n",
    "steering2_fixed = np.concatenate(steering2, axis=0)[:,1]\n",
    "#ax[0].hist(steering_fixed, bins=30)\n",
    "#ax[1].hist(steering2_fixed, bins=20)\n",
    "plt.hist(steering2_fixed, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compare_tf_tflite(model, tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ac1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.test_ds = (\n",
    "        test_dataset.shuffle(tr.hyperparameters.TRAIN_BATCH_SIZE * 10)\n",
    "        .repeat()\n",
    "        .batch(tr.hyperparameters.TEST_BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf68b72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 15\n",
    "image_batch, label_batch = next(iter(tr.test_ds))\n",
    "pred_batch = best_model.predict(\n",
    "        tf.slice(image_batch, [0, 0, 0, 0], [NUM_SAMPLES, -1, -1, -1])\n",
    ")\n",
    "utils.show_test_batch(\n",
    "    image_batch.numpy(), label_batch.numpy(), pred_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint = sorted(\n",
    "    [\n",
    "        d\n",
    "        for d in os.listdir(tr.checkpoint_path)\n",
    "        if os.path.isdir(os.path.join(tr.checkpoint_path, d))\n",
    "    ]\n",
    ")[-1]\n",
    "last_tflite = utils.generate_tflite(tr.checkpoint_path, last_checkpoint)\n",
    "utils.save_tflite(last_tflite, tr.checkpoint_path, \"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_sample(features):\n",
    "    image = features[\"image\"]\n",
    "    label = [features[\"throttle\"], features[\"steer\"]]\n",
    "    return image, label\n",
    "\n",
    "from openbot import tfrecord_utils\n",
    "test_dataset = (\n",
    "        tf.data.TFRecordDataset(tr.test_data_dir, num_parallel_reads=AUTOTUNE)\n",
    "        .map(tfrecord_utils.parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n",
    "        .map(process_test_sample, num_parallel_calls=AUTOTUNE)\n",
    "    )\n",
    "tr.test_ds = (\n",
    "        test_dataset.shuffle(tr.hyperparameters.TRAIN_BATCH_SIZE * 10)\n",
    "        .repeat()\n",
    "        .batch(tr.hyperparameters.TEST_BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 15\n",
    "image_batch, label_batch = next(iter(tr.test_ds))\n",
    "pred_batch = best_model.predict(\n",
    "        tf.slice(image_batch, [0, 0, 0, 0], [NUM_SAMPLES, -1, -1, -1])\n",
    ")\n",
    "utils.show_test_batch(\n",
    "    image_batch.numpy(), label_batch.numpy(), pred_batch\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29c9d606",
   "metadata": {},
   "source": [
    "## Save the notebook as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_notebook()\n",
    "current_file = \"policy_learning.ipynb\"\n",
    "output_file = os.path.join(tr.log_path, \"notebook.html\")\n",
    "utils.output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
