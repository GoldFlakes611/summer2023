{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these path\n",
    "MODEL_SAVE_PATH = \"models\"\n",
    "\n",
    "DATA = [\n",
    "    # TFRecord or Dataset Directory\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import pathlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import random\n",
    "from scipy import signal\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models import get_model\n",
    "from sampler import ImageSampler\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize Data Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageSampler(DATA)\n",
    "dataset.prepare()\n",
    "\n",
    "train_test_split = 0.8\n",
    "batch_size = 256\n",
    "train_size = int(len(dataset) * train_test_split)\n",
    "trainset, testset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "print(f\"Training: {len(trainset)}, Testing {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"classic\")\n",
    "fig, axes = plt.subplots(2, 6, figsize=(25, 8))\n",
    "axes = axes.flatten()\n",
    "for i in range(12):\n",
    "    img, steering, throttle = dataset[random.randint(0, len(dataset))]\n",
    "    axes[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f\"{steering: .4f}, {throttle: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_metric(pred, act):\n",
    "    angle_true = act[:, 0]\n",
    "    angle_pred = pred[:, 0]\n",
    "    turns = torch.abs(angle_true) > 0.1\n",
    "    logits = torch.sign(angle_pred[turns]) == torch.sign(angle_true[turns])\n",
    "    return torch.sum(logits.float()), len(logits)\n",
    "\n",
    "def angle_metric(pred, act):\n",
    "    angle_true = act[:, 0]\n",
    "    angle_pred = pred[:, 0]\n",
    "    logits = torch.abs(angle_true - angle_pred) < 0.1\n",
    "    return torch.mean(logits.float())\n",
    "\n",
    "def loss_fn(steering, throttle, steering_pred, throttle_pred, throttle_weight):\n",
    "    steering_loss = ((steering - steering_pred)**2).mean()\n",
    "    throttle_loss = ((throttle - throttle_pred)**2).mean()\n",
    "    loss = steering_loss + throttle_weight * throttle_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, save_dir, model: torch.nn.Module, optim: torch.optim.Optimizer, turning_weight=5, epochs=200):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.turning_weight = turning_weight\n",
    "        self.epochs = epochs\n",
    "\n",
    "        self.save_dir = pathlib.Path(save_dir).joinpath(model.NAME)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.train_log = []  # loss, angle, direction\n",
    "        self.validation_log = []  # loss, angle, direction\n",
    "\n",
    "        self.best_loss = np.inf\n",
    "        self.best_angle_metric = 0\n",
    "        self.best_direction_metric = 0\n",
    "\n",
    "        self.i = 0\n",
    "\n",
    "    def load(self, fname):\n",
    "        data = np.load(fname)\n",
    "        self.i = data[\"i\"]\n",
    "        self.train_log = data[\"train_log\"].tolist()\n",
    "        self.validation_log = data[\"validation_log\"].tolist()\n",
    "        self.best_loss = data[\"best_loss\"]\n",
    "        self.best_angle_metric = data[\"best_angle_metric\"]\n",
    "        self.best_direction_metric = data[\"best_direction_metric\"]\n",
    "\n",
    "    def save(self, fname):\n",
    "        torch.save({\n",
    "            \"state\": self.model.state_dict(),\n",
    "            \"optim\": self.optim.state_dict(),\n",
    "        }, os.path.join(self.save_dir, f\"last.pth\"))\n",
    "\n",
    "        np.savez_compressed(\n",
    "            fname,\n",
    "            train_log=self.train_log,\n",
    "            validation_log=self.validation_log,\n",
    "            i=self.i,\n",
    "            best_loss=self.best_loss,\n",
    "            best_angle_metric=self.best_angle_metric,\n",
    "            best_direction_metric=self.best_direction_metric\n",
    "        )\n",
    "\n",
    "    def train(self, sampler_train, sampler_test):\n",
    "        epochs = self.epochs\n",
    "        batches_train = len(sampler_train)\n",
    "        batches_test = len(sampler_test)\n",
    "\n",
    "        epochs_bar = tqdm(total=epochs)\n",
    "        epochs_bar.set_description(\"Epochs\")\n",
    "        batch_bar = tqdm(total=batches_train)\n",
    "\n",
    "        epochs_bar.update(self.i)\n",
    "        epochs_bar.refresh()\n",
    "        while self.i < epochs:\n",
    "            #Training\n",
    "            batch_bar.set_description(\"Training\")\n",
    "            batch_bar.reset(batches_train)\n",
    "            for i, (img, steering, throttle) in enumerate(sampler_train):\n",
    "                Y = torch.stack([steering, throttle], dim=1).type(torch.float32).to(device)\n",
    "                #Tensor Processing\n",
    "                X = img.to(device).permute(0, 3, 1, 2) / 256 #Starting dimensions [1,100,90,160] -> After permute [100, 1, 90, 160] (Pytorch Tensor format[Number, Channels, Height, Width])\n",
    "\n",
    "                #Using the model for inference\n",
    "                self.optim.zero_grad()\n",
    "                Y_pred = self.model(X)\n",
    "\n",
    "                #Loss calculation and backpropogation\n",
    "                loss = loss_fn(Y[:, 0], Y[:, 1], Y_pred[:, 0], Y_pred[:, 1], throttle_weight=0.2)\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "                #Some extra metrics to grade performance by\n",
    "                loss = loss.item()\n",
    "                ang_metric = angle_metric(Y_pred, Y).item()\n",
    "                dir_metric, num = direction_metric(Y_pred, Y)\n",
    "                dir_metric = (dir_metric / num).item() if num > 0 else np.nan\n",
    "\n",
    "                #Debugging/Logging\n",
    "                self.train_log.append((loss, ang_metric, dir_metric))\n",
    "\n",
    "                batch_bar.set_postfix(ordered_dict=OrderedDict(\n",
    "                    Loss=f\"{loss: .3f}\",\n",
    "                    Best_loss=f\"{self.best_loss: .3f}\",\n",
    "                    Angle=f\"{ang_metric: .3f}\",\n",
    "                    Best_angle=f\"{self.best_angle_metric: .3f}\",\n",
    "                    Direction=f\"{dir_metric: .3f}\",\n",
    "                    Best_Dir=f\"{self.best_direction_metric: .3f}\"\n",
    "                ))\n",
    "                batch_bar.update()\n",
    "\n",
    "            #Validation (Testing)\n",
    "            batch_bar.set_description(\"Validation\")\n",
    "            batch_bar.reset(batches_test)\n",
    "            validation_avg = torch.zeros(batches_test, 3)  # loss, angle, direction_sum\n",
    "            direction_num = 0\n",
    "\n",
    "            for j, (img, steering, throttle) in enumerate(sampler_test):\n",
    "                Y = torch.stack([steering, throttle], dim=1).type(torch.float32).to(device)\n",
    "                X = img.to(device).permute(0, 3, 1, 2) / 256\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    Y_pred = self.model(X)\n",
    "\n",
    "                # Test on Validation Set\n",
    "                val_loss = loss_fn(Y[:, 0], Y[:, 1], Y_pred[:, 0], Y_pred[:, 1], throttle_weight=0.2)\n",
    "                ang_metric = angle_metric(Y_pred, Y)\n",
    "                dir_metric, num = direction_metric(Y_pred, Y)\n",
    "                validation_avg[j] = torch.stack([val_loss, ang_metric, dir_metric])\n",
    "                direction_num += num\n",
    "\n",
    "                batch_bar.set_postfix(ordered_dict=OrderedDict(\n",
    "                    Loss=f\"{val_loss.item(): .3f}\",\n",
    "                    Best_loss=f\"{self.best_loss: .3f}\",\n",
    "                    Angle=f\"{ang_metric.item(): .3f}\",\n",
    "                    Best_angle=f\"{self.best_angle_metric: .3f}\",\n",
    "                    Direction=f\"{dir_metric.item() / num if num > 0 else np.nan: .3f}\",\n",
    "                    Best_Dir=f\"{self.best_direction_metric: .3f}\"\n",
    "                ))\n",
    "                batch_bar.update()\n",
    "\n",
    "            validation_avg = validation_avg.sum(dim=0)\n",
    "            validation_avg[:2] /= batches_test\n",
    "            validation_avg[2] /= direction_num\n",
    "\n",
    "            #Debugging/Logging\n",
    "            self.validation_log.append(validation_avg.tolist())\n",
    "\n",
    "            val_loss, ang_metric, dir_metric = self.validation_log[-1]\n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "                if self.best_loss < 0.02:\n",
    "                    torch.save({\n",
    "                        \"state\": self.model.state_dict(),\n",
    "                        \"optim\": self.optim.state_dict(),\n",
    "                    }, os.path.join(self.save_dir, f\"best_loss.pth\"))\n",
    "            if ang_metric > self.best_angle_metric:\n",
    "                self.best_angle_metric = ang_metric\n",
    "                if self.best_angle_metric > 0.6:\n",
    "                    torch.save({\n",
    "                        \"state\": self.model.state_dict(),\n",
    "                        \"optim\": self.optim.state_dict(),\n",
    "                    }, os.path.join(self.save_dir, f\"best_angle.pth\"))\n",
    "            if dir_metric > self.best_direction_metric:\n",
    "                self.best_direction_metric = dir_metric\n",
    "                if self.best_direction_metric > 0.8:\n",
    "                    torch.save({\n",
    "                        \"state\": self.model.state_dict(),\n",
    "                        \"optim\": self.optim.state_dict(),\n",
    "                    }, os.path.join(self.save_dir, f\"best_dir.pth\"))\n",
    "\n",
    "            # Slow for large model\n",
    "            # torch.save({\n",
    "            #     \"state\": self.model.state_dict(),\n",
    "            #     \"optim\": self.optim.state_dict(),\n",
    "            # }, os.path.join(self.save_dir, f\"last.pth\"))\n",
    "\n",
    "            batch_bar.refresh()\n",
    "            epochs_bar.update()\n",
    "            self.i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [\n",
    "    # Pytorch Hub\n",
    "    # \"alexnet\",\n",
    "    # \"vgg16_bn\",\n",
    "    \"resnet34\",\n",
    "    \"googlenet\",\n",
    "    # Custom\n",
    "    \"cnn\"\n",
    "]\n",
    "\n",
    "save_dir = pathlib.Path(MODEL_SAVE_PATH)\n",
    "load_trainer = True\n",
    "\n",
    "for model_name in all_models:\n",
    "    print(f\"Training {model_name}\")\n",
    "\n",
    "    if model_name in trainers:\n",
    "        trainer = trainers[model_name]\n",
    "        # move the model back to device\n",
    "        trainer.model = trainer.model.to(device)\n",
    "        trainer.optim.load_state_dict(trainer.optim.state_dict())\n",
    "\n",
    "    else:\n",
    "        model = get_model(model_name)().to(device)\n",
    "        optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "        save_model = save_dir.joinpath(model.NAME).joinpath(\"last.pth\")\n",
    "        if save_model.exists():\n",
    "            print(f\"Loading model from {save_model}\")\n",
    "            state = torch.load(save_model)\n",
    "            model.load_state_dict(state[\"state\"])\n",
    "            optimizer.load_state_dict(state[\"optim\"])\n",
    "\n",
    "        trainer = Trainer(save_dir, model, optimizer, turning_weight=5, epochs=1000)\n",
    "        save_trainer = save_dir.joinpath(model.NAME).joinpath(\"trainer_log.npz\")\n",
    "        if load_trainer and save_trainer.exists():\n",
    "            print(f\"Loading trainer from {save_trainer}\")\n",
    "            trainer.load(save_trainer)\n",
    "        trainers[model_name] = trainer\n",
    "        del model, optimizer\n",
    "\n",
    "    if trainer.i < trainer.epochs:\n",
    "        try:\n",
    "            sampler_train = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=multiprocessing.cpu_count(), persistent_workers=True)\n",
    "            sampler_test = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=multiprocessing.cpu_count(), persistent_workers=True)\n",
    "            trainer.train(sampler_train, sampler_test)\n",
    "        finally:\n",
    "            # Move the model to CPU\n",
    "            trainer.model = trainer.model.to('cpu')\n",
    "            trainer.optim.load_state_dict(trainer.optim.state_dict())\n",
    "            trainer.save(pathlib.Path(MODEL_SAVE_PATH).joinpath(trainer.model.NAME).joinpath(\"trainer_log.npz\"))\n",
    "\n",
    "            try:\n",
    "                # Close iterator\n",
    "                sampler_train._iterator._shutdown_workers()\n",
    "                sampler_test._iterator._shutdown_workers()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload\n",
    "import importlib\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean cache\n",
    "g = globals()\n",
    "del_list = [\"model\", \"trainer\", \"optimizer\"] + [f\"_{i}\" for i in range(1000)] + [f\"_i{i}\" for i in range(1000)]\n",
    "for i in del_list:\n",
    "    if i in g:\n",
    "        del g[i]\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = DataLoader(dataset, batch_size=12, shuffle=True)\n",
    "test_iterator = iter(test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trainers[\"cnn\"]\n",
    "model = trainer.model.to(device)\n",
    "train_log = np.array(trainer.train_log)\n",
    "validation_log = np.array(trainer.validation_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, steering, throttle = next(test_iterator)\n",
    "Y = torch.stack([steering, throttle], dim=1).type(torch.float32).to(device)\n",
    "X = img.to(device).permute(0, 3, 1, 2) / 256\n",
    "with torch.no_grad():\n",
    "    Y_pred = model(X)\n",
    "\n",
    "val_loss = loss_fn(Y[:, 0], Y[:, 1], Y_pred[:, 0], Y_pred[:, 1], throttle_weight=0.2)\n",
    "print(val_loss)\n",
    "\n",
    "plt.style.use(\"classic\")\n",
    "fig, axes = plt.subplots(2, 6, figsize=(40, 8))\n",
    "axes = axes.flatten()\n",
    "p_fn = lambda x: ','.join([f'{i: .4f}' for i in x])\n",
    "\n",
    "for i in range(12):\n",
    "    axes[i].imshow(img[i].cpu().numpy()[...,::-1])\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f\"Model:{p_fn(Y_pred[i].tolist())}\\nTrue: {p_fn([steering[i], throttle[i]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_openbot = get_model_openbot(model.NAME)()\n",
    "model_openbot.load_state_dict(model.state_dict())\n",
    "dummy_input = torch.randn(1, 224, 224, 3)\n",
    "torch.onnx.export(model_openbot, dummy_input, model.NAME + \".onnx\", verbose=False, input_names=[\"img_input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"classic\")\n",
    "plt.figure(figsize=(25, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_log[:, 0], '.', markersize=1, color=\"black\")\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(validation_log[:, 0], '-', markersize=3, color=\"black\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(signal.convolve(train_log[:, 0], np.ones(100) / 100, 'valid'), '.', markersize=1, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Angle Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"classic\")\n",
    "plt.figure(figsize=(25, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_log[:, 1], '.', markersize=1, color=\"black\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(validation_log[:, 1], '-', markersize=3, color=\"black\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(signal.convolve(train_log[:, 1], np.ones(100) / 100, 'valid'), '.', markersize=1, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Direction Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"classic\")\n",
    "plt.figure(figsize=(25, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_log[:, 2], '.', markersize=1, color=\"black\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(validation_log[:, 2], '-', markersize=3, color=\"black\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(signal.convolve(train_log[:, 2], np.ones(100) / 100, 'valid'), '.', markersize=1, color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
